{"cells":[{"cell_type":"markdown","metadata":{"id":"vUXNQZtwEYiQ"},"source":["# Running MegaDetector on camera trap images using Google Colab\n","\n","[Open this notebook in Colab](https://colab.research.google.com/github/microsoft/CameraTraps/blob/main/detection/megadetector_colab.ipynb)\n","\n","Adapted from previous versions by [@louis030195](https://github.com/louis030195)\n","and [@alsnothome](https://github.com/alsnothome).\n","\n","Also see the [MegaDetector guide on GitHub](https://github.com/ecologize/CameraTraps/blob/main/megadetector.md).\n","\n","This notebook is designed to load camera trap images that have already been uploaded to Google Drive. If you don't have your own images on Google Drive, this notebook will show you how to download some sample images from [LILA](https://lila.science).\n","\n","MegaDetector output is saved in a .json file whose format is described  [here](https://github.com/ecologize/CameraTraps/tree/main/api/batch_processing#batch-processing-api-output-format). The last cell in this notebook will give you some pointers on how users typically work with MegaDetector output."]},{"cell_type":"markdown","metadata":{"id":"9aUlxnm7cnWy"},"source":["## Set up the Colab instance to run on a GPU accelerator\n","\n","\n","Navigate to Edit→Notebook Settings and select \"GPU\" from the \"Hardware accelerator\" drop-down menu."]},{"cell_type":"markdown","metadata":{"id":"LUyqKSAWRGNw"},"source":["## Install dependencies, download the model, set up your PYTHONPATH\n","\n","From here on, you'll start seeing a mix of code and Linux system commands. System commands are prefixed by a shebang `!`, which tells this notebook to execute them on the command line."]},{"cell_type":"markdown","metadata":{"id":"VtNnMxtte0EF"},"source":["### Install required Python packages\n","\n","This may take 2-3 minutes."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EMEkgpy6T0pr","executionInfo":{"status":"ok","timestamp":1686787610057,"user_tz":180,"elapsed":5955,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"adb891f9-2fa1-4c21-d0b6-e66528059fba","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting humanfriendly\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Installing collected packages: humanfriendly\n","Successfully installed humanfriendly-10.0\n"]}],"source":["pip install humanfriendly jsonpickle"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7hQB4Ifx8M1k","executionInfo":{"status":"ok","timestamp":1686787618713,"user_tz":180,"elapsed":5363,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"35175125-4863-4227-820b-8416da625cff","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["pip install torch torchvision"]},{"cell_type":"code","source":["import site; site.getsitepackages()\n"],"metadata":{"id":"9TnMQa_tQW-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hXn_-PZqTWB4"},"source":["### Download the MegaDetector model files\n","\n","We'll download both MegaDetector v5a and v5b.  See the [release notes](https://github.com/ecologize/CameraTraps/releases/tag/v5.0) for information about the differences between the two models."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"s5uwmpmaTZMX","executionInfo":{"status":"ok","timestamp":1686787633261,"user_tz":180,"elapsed":9381,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"bb7639fc-5102-4573-b346-5bb02baba77c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-15 00:04:11--  https://github.com/ecologize/CameraTraps/releases/download/v5.0/md_v5a.0.0.pt\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/agentmorris/MegaDetector/releases/download/v5.0/md_v5a.0.0.pt [following]\n","--2023-06-15 00:04:11--  https://github.com/agentmorris/MegaDetector/releases/download/v5.0/md_v5a.0.0.pt\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/643058819/2e148df3-d729-406b-a7a6-b3ca5488145a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230615T000412Z&X-Amz-Expires=300&X-Amz-Signature=e144fc410be0cc4085ea36ce0f90ec0351cf3730439c02c0ef22ba826d79b030&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=643058819&response-content-disposition=attachment%3B%20filename%3Dmd_v5a.0.0.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-06-15 00:04:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/643058819/2e148df3-d729-406b-a7a6-b3ca5488145a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230615T000412Z&X-Amz-Expires=300&X-Amz-Signature=e144fc410be0cc4085ea36ce0f90ec0351cf3730439c02c0ef22ba826d79b030&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=643058819&response-content-disposition=attachment%3B%20filename%3Dmd_v5a.0.0.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 280766885 (268M) [application/octet-stream]\n","Saving to: ‘/content/md_v5a.0.0.pt’\n","\n","/content/md_v5a.0.0 100%[===================>] 267.76M  70.1MB/s    in 3.8s    \n","\n","2023-06-15 00:04:16 (69.9 MB/s) - ‘/content/md_v5a.0.0.pt’ saved [280766885/280766885]\n","\n","--2023-06-15 00:04:16--  https://github.com/ecologize/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/agentmorris/MegaDetector/releases/download/v5.0/md_v5b.0.0.pt [following]\n","--2023-06-15 00:04:16--  https://github.com/agentmorris/MegaDetector/releases/download/v5.0/md_v5b.0.0.pt\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/643058819/be853aa0-02fe-4697-894f-4c1af4a81b7f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230615T000416Z&X-Amz-Expires=300&X-Amz-Signature=05178f07a549fa54f862658839a2bb55ade39cef859ea47d2ad47cf85c09bfc2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=643058819&response-content-disposition=attachment%3B%20filename%3Dmd_v5b.0.0.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-06-15 00:04:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/643058819/be853aa0-02fe-4697-894f-4c1af4a81b7f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230615%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230615T000416Z&X-Amz-Expires=300&X-Amz-Signature=05178f07a549fa54f862658839a2bb55ade39cef859ea47d2ad47cf85c09bfc2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=643058819&response-content-disposition=attachment%3B%20filename%3Dmd_v5b.0.0.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 280766885 (268M) [application/octet-stream]\n","Saving to: ‘/content/md_v5b.0.0.pt’\n","\n","/content/md_v5b.0.0 100%[===================>] 267.76M  73.0MB/s    in 3.7s    \n","\n","2023-06-15 00:04:20 (73.3 MB/s) - ‘/content/md_v5b.0.0.pt’ saved [280766885/280766885]\n","\n"]}],"source":["!wget -O /content/md_v5a.0.0.pt https://github.com/ecologize/CameraTraps/releases/download/v5.0/md_v5a.0.0.pt\n","!wget -O /content/md_v5b.0.0.pt https://github.com/ecologize/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt"]},{"cell_type":"markdown","metadata":{"id":"nmJ6lQX8S4im"},"source":["### Clone the required git repos\n","This will copy the latest version of the Microsoft AI for Earth \"utilities\" and \"CameraTraps\" repositories from GitHub, as well as the YOLOv5 repo, all of which are required to run MegaDetector."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7qhltAaRSe1W","executionInfo":{"status":"ok","timestamp":1686787648397,"user_tz":180,"elapsed":10261,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"687b7ef5-8331-46a4-b8e5-776bd73fbeb4","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CameraTraps'...\n","remote: Enumerating objects: 16108, done.\u001b[K\n","remote: Counting objects: 100% (954/954), done.\u001b[K\n","remote: Compressing objects: 100% (414/414), done.\u001b[K\n","remote: Total 16108 (delta 547), reused 942 (delta 539), pack-reused 15154\u001b[K\n","Receiving objects: 100% (16108/16108), 181.31 MiB | 32.76 MiB/s, done.\n","Resolving deltas: 100% (9743/9743), done.\n","Cloning into 'ai4eutils'...\n","remote: Enumerating objects: 787, done.\u001b[K\n","remote: Counting objects: 100% (93/93), done.\u001b[K\n","remote: Compressing objects: 100% (56/56), done.\u001b[K\n","remote: Total 787 (delta 54), reused 52 (delta 37), pack-reused 694\u001b[K\n","Receiving objects: 100% (787/787), 2.59 MiB | 15.58 MiB/s, done.\n","Resolving deltas: 100% (469/469), done.\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 15978, done.\u001b[K\n","remote: Counting objects: 100% (147/147), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 15978 (delta 89), reused 111 (delta 70), pack-reused 15831\u001b[K\n","Receiving objects: 100% (15978/15978), 14.60 MiB | 23.92 MiB/s, done.\n","Resolving deltas: 100% (10962/10962), done.\n","Note: switching to 'c23a441c9df7ca9b1f275e8c8719c949269160d1'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at c23a441 Improved `dataset_stats()` YAML checks (#8125)\n"]}],"source":["!git clone https://github.com/ecologize/CameraTraps\n","!git clone https://github.com/microsoft/ai4eutils\n","!git clone https://github.com/ultralytics/yolov5/\n","!cd yolov5 && git checkout c23a441c9df7ca9b1f275e8c8719c949269160d1"]},{"cell_type":"markdown","metadata":{"id":"2pzfM5Y-iby1"},"source":["### Set `PYTHONPATH` to include `CameraTraps`, `ai4eutils`, and `yolov5`\n","\n","Add cloned git folders to the `PYTHONPATH` environment variable so that we can import their modules from any working directory.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"d8vanlgAOlEj","executionInfo":{"status":"ok","timestamp":1686787659942,"user_tz":180,"elapsed":317,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}}},"outputs":[],"source":["import os\n","os.environ['PYTHONPATH'] += \":/content/ai4eutils\"\n","os.environ['PYTHONPATH'] += \":/content/CameraTraps\"\n","os.environ['PYTHONPATH'] += \":/content/yolov5\""]},{"cell_type":"markdown","metadata":{"id":"JyjEgkCsOsak"},"source":["## Mount Google Drive in Colab\n","You can mount your Google Drive if you have your sample images there, or if want to save the results to your Google Drive.\n","\n","Once you run the cell below, you will be prompted to authorize Colab to access your Google Drive.  Your Google Drive folders will then be mounted under `/content/drive` and can be viewed and navigated in the Files pane in Colab.\n","\n","The method is described in [this Colab code snippet](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA)."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XYsrTTR7eF0r","executionInfo":{"status":"ok","timestamp":1686787690406,"user_tz":180,"elapsed":25701,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"3551b49e-2118-43af-ec16-c2db86b615ed","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yM3Dl0Bfe0EM"},"source":["## Download sample images\n","\n","We install Microsoft's [azcopy](https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10) utility, which we then use to download a few camera trap images from the [Snapshot Serengeti](http://lila.science/datasets/snapshot-serengeti) dataset hosted on [lila.science](http://lila.science).  If you are using your own data, you can skip this step."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gAkYScsLe0EM","executionInfo":{"status":"ok","timestamp":1686787698386,"user_tz":180,"elapsed":4068,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"3556a4af-2cf1-4df4-b492-52f89d53d708","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["azcopy_linux_amd64_10.19.0/azcopy\n","INFO: Scanning...\n","INFO: Autologin not specified.\n","INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n","\n","Job da28ed14-db45-eb4e-79dc-bb971e96e4de has started\n","Log file is located at: /root/.azcopy/da28ed14-db45-eb4e-79dc-bb971e96e4de.log\n","\n","\r100.0 %, 48 Done, 0 Failed, 0 Pending, 0 Skipped, 48 Total, 2-sec Throughput (Mb/s): 118.9085\n","\n","\n","Job da28ed14-db45-eb4e-79dc-bb971e96e4de summary\n","Elapsed Time (Minutes): 0.0336\n","Number of File Transfers: 48\n","Number of Folder Property Transfers: 0\n","Number of Symlink Transfers: 0\n","Total Number of Transfers: 48\n","Number of File Transfers Completed: 48\n","Number of Folder Transfers Completed: 0\n","Number of File Transfers Failed: 0\n","Number of Folder Transfers Failed: 0\n","Number of File Transfers Skipped: 0\n","Number of Folder Transfers Skipped: 0\n","TotalBytesTransferred: 29942558\n","Final Job Status: Completed\n","\n"]}],"source":["%%bash\n","\n","# Download azcopy\n","wget -q -O azcopy_linux.tar.gz https://aka.ms/downloadazcopy-v10-linux\n","tar -xvzf azcopy_linux.tar.gz --wildcards */azcopy --strip 1\n","rm azcopy_linux.tar.gz\n","chmod u+x azcopy\n","\n","# Copy a few Snapshot Serengeti images to a local directory\n","DATASET_URL=\"https://lilablobssc.blob.core.windows.net/snapshotserengeti-unzipped/\"\n","SAMPLE_DIR=\"S1/D05/D05_R4\"\n","LOCAL_DIR=\"/content/snapshotserengeti\"\n","\n","./azcopy cp \"${DATASET_URL}${SAMPLE_DIR}\" \"${LOCAL_DIR}\" --recursive"]},{"cell_type":"markdown","metadata":{"id":"Lkugt7r3uUEr"},"source":["## MegaDetector batch processing\n","\n","This step executes the Python script `run_detector_batch.py` from the CameraTraps repo. It has three mandatory arguments and one optional:\n","\n","1. Path to the MegaDetector model file\n","2. A folder containing images.  This notebook points to the folder where we just put our Snapshot Serengeti images; if your images were already on Google Drive, replace `[Image_Folder]` with your folder name.\n","3. The output JSON file location and name."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pSIH-k0nfi73","executionInfo":{"status":"ok","timestamp":1686787705632,"user_tz":180,"elapsed":297,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}}},"outputs":[],"source":["images_dir = '/content/snapshotserengeti'\n","\n","# Choose a location for the output JSON file\n","output_file_path = '/content/drive/My Drive/snapshotserengeti-test/snapshot-serengeti-megadetector-results.json'"]},{"cell_type":"markdown","metadata":{"id":"Bsvuux-yhpLw"},"source":["Here we pass the Python variable value `output_file_path` you specified above to the bash commands below using `$` (double quoting as there are spaces in this path), to run the script. This is so that we can refer to the output file path later for visualization."]},{"cell_type":"markdown","metadata":{"id":"3YZs9wT1sAgV"},"source":["# Run the detection script\n","\n","There are actually two variants of MegaDetector v5, called \"v5a\" and \"v5b\".  By default this notebook runs MDv5a; change \"md_v5a.0.0.pt\" to \"md_v5b.0.0.pt\" to run MDv5b instead.\n","\n","Both run at the same speed; if you are in a Colab session with a GPU accelerator, you should be able to process around four images per second."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3AOKfviGuTNg","executionInfo":{"status":"ok","timestamp":1686787739590,"user_tz":180,"elapsed":27756,"user":{"displayName":"Roberto Cavalcanti","userId":"04696245716915233937"}},"outputId":"2d7c8ecd-30c5-43ac-a52c-60c038a1aca5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: output_file /content/drive/My Drive/snapshotserengeti-test/snapshot-serengeti-megadetector-results.json already exists and will be overwritten\n","48 image files found in the input directory\n","PyTorch reports 1 available CUDA devices\n","GPU available: True\n","Using PyTorch version 2.0.1+cu118\n","Fusing layers... \n","Model summary: 574 layers, 139990096 parameters, 0 gradients\n","Sending model to GPU\n","Loaded model in 11.78 seconds\n","Loaded model in 11.78 seconds\n","  0% 0/48 [00:00<?, ?it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0120.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","  2% 1/48 [00:03<03:06,  3.98s/it]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0086.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0116.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","  6% 3/48 [00:04<00:49,  1.10s/it]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0114.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","  8% 4/48 [00:04<00:33,  1.33it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0085.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0106.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 12% 6/48 [00:04<00:17,  2.35it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0102.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0094.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 17% 8/48 [00:04<00:11,  3.47it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0098.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0087.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 21% 10/48 [00:04<00:08,  4.64it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0089.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0080.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 25% 12/48 [00:05<00:06,  5.78it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0105.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0113.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 29% 14/48 [00:05<00:05,  6.73it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0097.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0093.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 33% 16/48 [00:05<00:04,  7.61it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0107.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0115.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 38% 18/48 [00:05<00:03,  8.32it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0111.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0108.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 42% 20/48 [00:05<00:03,  8.84it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0119.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0088.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 46% 22/48 [00:05<00:02,  9.38it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0090.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0078.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 50% 24/48 [00:06<00:02,  9.67it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0079.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0122.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 54% 26/48 [00:06<00:02,  9.87it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0081.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0103.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 58% 28/48 [00:06<00:01, 10.02it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0077.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0112.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 62% 30/48 [00:06<00:01, 10.16it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0084.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0099.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 67% 32/48 [00:06<00:01, 10.21it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0092.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0083.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 71% 34/48 [00:07<00:01, 10.30it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0110.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0100.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 75% 36/48 [00:07<00:01, 10.35it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0091.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0104.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 79% 38/48 [00:07<00:00, 10.35it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0075.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0095.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 83% 40/48 [00:07<00:00, 10.37it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0121.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0076.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 88% 42/48 [00:07<00:00, 10.27it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0096.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0101.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 92% 44/48 [00:08<00:00, 10.30it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0082.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0117.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n"," 96% 46/48 [00:08<00:00, 10.38it/s]PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0109.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","PTDetector: image /content/snapshotserengeti/D05_R4/S1_D05_R4_PICT0118.JPG failed during inference: 'Upsample' object has no attribute 'recompute_scale_factor'\n","\n","100% 48/48 [00:08<00:00,  5.66it/s]\n","Finished inference for 48 images in 24.18 seconds (1.99 images per second)\n","Output file saved at /content/drive/My Drive/snapshotserengeti-test/snapshot-serengeti-megadetector-results.json\n","Done!\n"]}],"source":["!python /content/CameraTraps/detection/run_detector_batch.py md_v5a.0.0.pt \"$images_dir\" \"$output_file_path\" --recursive --output_relative_filenames --quiet"]},{"cell_type":"markdown","metadata":{"id":"-tHu5WUGDpcd"},"source":["## Visualize batch processing script outputs\n","\n","Here we use the `visualize_detector_output.py` in the `visualization` folder of the Camera Traps repo to see the output of the MegaDetector visualized on our images. It will save images annotated with the results (original images will *not* be modified) to the folder you specify here.\n","\n","The scripts take in a number of optional parameters to control output image size and how many are sampled (if you've processed a lot of images but only want to visualize the results on a few) - take a look at the `main()` function in the script to see what other parameters are available."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"en3TbCftkWDE"},"outputs":[],"source":["# Render bounding boxes on our images\n","visualization_dir = '/content/visualized_images'\n","!python /content/CameraTraps/md_visualization/visualize_detector_output.py \"$output_file_path\" \"$visualization_dir\" --confidence 0.2 --images_dir \"$images_dir\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AglNEK0goyjA"},"outputs":[],"source":["# Show the images with bounding boxes in Colab\n","import os\n","from PIL import Image\n","\n","for viz_file_name in os.listdir(visualization_dir):\n","  print(viz_file_name)\n","  im = Image.open(os.path.join(visualization_dir, viz_file_name))\n","  display(im)"]},{"cell_type":"markdown","metadata":{"id":"ycce0Oi_e0EQ"},"source":["# Next steps\n","\n","Now that you have run MegaDetector on a few images, here are some pointers to help you take advantage of MegaDetector to label your survey images more quickly.\n","\n","### Ways to use the output .json in a camera trap image processing workflow\n","\n","#### 1. Timelapse\n","\n","[Timelapse](http://saul.cpsc.ucalgary.ca/timelapse/pmwiki.php?n=Main.HomePage) is an open-source tool for annotating camera trap images. We have worked with the Timelapse developer to integrate MegaDetector results into Timelapse, so a user can:\n","\n","- Select or sort images based on whether they contain animal or people or vehicles.\n","- View bounding boxes during additional manual annotation steps\n","\n","See the [Timelapse Image Recognition Guide](https://saul.cpsc.ucalgary.ca/timelapse/uploads/Guides/TimelapseImageRecognitionGuide.pdf) for more information.\n","\n","![Screenshot showing the Timelapse application with MegaDetector output, shown as a bounding box around the detected animal](https://github.com/ecologize/CameraTraps/blob/main/api/batch_processing/integration/images/tl_boxes.jpg?raw=1)\n","\n","\n","#### 2. Separating images into folders that contain animals/people/vehicles/nothing\n","\n","Some MegaDetector users do image review without Timelapse, by moving the images to separate folders containing animals/people/vehicles/nothing according to MegaDetector output. You can use the script [separate_detections_into_folders.py](https://github.com/ecologize/CameraTraps/blob/master/api/batch_processing/postprocessing/separate_detections_into_folders.py) for this.\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/microsoft/CameraTraps/blob/main/detection/megadetector_colab.ipynb","timestamp":1686787434634}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}